{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic-pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMWttUdCUps2xkFgz4mzQoN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hotchya/basic-pytorch/blob/main/basic_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK7CdhR8g7sL",
        "outputId": "7e7efcb6-aacc-4706-e46f-30c377fbf1a3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May  2 07:16:46 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUotmGBGhL0q",
        "outputId": "d273b504-952e-41cd-9c18-92472fcb8b07"
      },
      "source": [
        "!git clone https://github.com/hotchya/basic-pytorch.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'basic-pytorch'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 44 (delta 15), reused 36 (delta 10), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klWruzRLhwdt",
        "outputId": "944e3380-443f-4e16-9791-e5f8977216fb"
      },
      "source": [
        "%cd basic-pytorch"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/basic-pytorch/basic-pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZI-Bl2kiAlh",
        "outputId": "5f94aa91-f915-4ab9-eaea-5d0b899c643a"
      },
      "source": [
        "!python3 main.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "9913344it [04:18, 38332.39it/s]\n",
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "29696it [00:00, 431605.64it/s]\n",
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "1649664it [00:46, 35702.12it/s]                 \n",
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "5120it [00:00, 21074422.45it/s]\n",
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Processing...\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
            "Done!\n",
            "Total parameter number: 44426 \n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.306821\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.155466\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.405518\n",
            "save model : LeNet5.MNIST.pth.tar\n",
            "\n",
            "Test set: Average loss: 0.3990, Accuracy: 8731/10000 (87.31%), Best Acc : 87.31\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.474618\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.190793\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.068134\n",
            "save model : LeNet5.MNIST.pth.tar\n",
            "\n",
            "Test set: Average loss: 0.1741, Accuracy: 9444/10000 (94.44%), Best Acc : 94.44\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.240413\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.116639\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.086404\n",
            "save model : LeNet5.MNIST.pth.tar\n",
            "\n",
            "Test set: Average loss: 0.0872, Accuracy: 9727/10000 (97.27%), Best Acc : 97.27\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.076343\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.060548\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.081479\n",
            "save model : LeNet5.MNIST.pth.tar\n",
            "\n",
            "Test set: Average loss: 0.0545, Accuracy: 9824/10000 (98.24%), Best Acc : 98.24\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.075116\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.058913\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.065601\n",
            "\n",
            "Test set: Average loss: 0.1130, Accuracy: 9624/10000 (96.24%), Best Acc : 98.24\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.094521\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.034824\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.066816\n",
            "save model : LeNet5.MNIST.pth.tar\n",
            "\n",
            "Test set: Average loss: 0.0476, Accuracy: 9830/10000 (98.30%), Best Acc : 98.3\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.043814\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.041614\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.013816\n",
            "\n",
            "Test set: Average loss: 0.0581, Accuracy: 9800/10000 (98.00%), Best Acc : 98.3\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.028353\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.072556\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.040509\n",
            "save model : LeNet5.MNIST.pth.tar\n",
            "\n",
            "Test set: Average loss: 0.0390, Accuracy: 9869/10000 (98.69%), Best Acc : 98.69\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.022368\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.015276\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.046563\n",
            "save model : LeNet5.MNIST.pth.tar\n",
            "\n",
            "Test set: Average loss: 0.0322, Accuracy: 9886/10000 (98.86%), Best Acc : 98.86\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.014872\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.038203\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.035556\n",
            "\n",
            "Test set: Average loss: 0.0325, Accuracy: 9884/10000 (98.84%), Best Acc : 98.86\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.014024\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.017832\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.030296\n",
            "save model : LeNet5.MNIST.pth.tar\n",
            "\n",
            "Test set: Average loss: 0.0332, Accuracy: 9890/10000 (98.90%), Best Acc : 98.9\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.025601\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.026381\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.012728\n",
            "\n",
            "Test set: Average loss: 0.0639, Accuracy: 9778/10000 (97.78%), Best Acc : 98.9\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.066370\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.019459\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.020876\n",
            "save model : LeNet5.MNIST.pth.tar\n",
            "\n",
            "Test set: Average loss: 0.0334, Accuracy: 9899/10000 (98.99%), Best Acc : 98.99\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.009150\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.033242\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.012324\n",
            "\n",
            "Test set: Average loss: 0.0314, Accuracy: 9890/10000 (98.90%), Best Acc : 98.99\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.031308\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.013561\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.036010\n",
            "\n",
            "Test set: Average loss: 0.0403, Accuracy: 9871/10000 (98.71%), Best Acc : 98.99\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.021565\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.012094\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.010277\n",
            "\n",
            "Test set: Average loss: 0.0474, Accuracy: 9845/10000 (98.45%), Best Acc : 98.99\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.019506\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.019119\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.008361\n",
            "\n",
            "Test set: Average loss: 0.0300, Accuracy: 9893/10000 (98.93%), Best Acc : 98.99\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.027816\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.009078\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.005679\n",
            "\n",
            "Test set: Average loss: 0.0339, Accuracy: 9885/10000 (98.85%), Best Acc : 98.99\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.014272\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.005901\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.007938\n",
            "\n",
            "Test set: Average loss: 0.0295, Accuracy: 9898/10000 (98.98%), Best Acc : 98.99\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.016375\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.004813\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.011898\n",
            "save model : LeNet5.MNIST.pth.tar\n",
            "\n",
            "Test set: Average loss: 0.0264, Accuracy: 9912/10000 (99.12%), Best Acc : 99.12\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.004829\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.000960\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.011418\n",
            "\n",
            "Test set: Average loss: 0.0272, Accuracy: 9907/10000 (99.07%), Best Acc : 99.12\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.001907\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.028866\n",
            "Exception in thread Thread-47:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 492, in Client\n",
            "    c = SocketClient(address)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 620, in SocketClient\n",
            "    s.connect(address)\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 158, in <module>\n",
            "    train(epoch)\n",
            "  File \"main.py\", line 25, in train\n",
            "    for batch_idx, (data, target) in enumerate(train_loader):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1182, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1138, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 986, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/queue.py\", line 179, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 300, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG2x4sr78Y95"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}